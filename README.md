
# ğŸ§© ML Pipeline: Tokenization & Classification

This project demonstrates an **end-to-end machine learning pipeline** for text classification using **Python** and **scikit-learn**.  
It includes everything from preprocessing raw text to training a model and scoring new data.

---

## ğŸš€ Features
- ğŸ“‚ Load datasets from CSV (`id`, `text`, `label`)
- âœ¨ Text preprocessing with **TF-IDF vectorization**
- ğŸ¤– Model training with **Logistic Regression**
- ğŸ’¾ Save and reuse vectorizers and models with **Joblib**
- ğŸ“Š Score new datasets and export results to CSV

---

## ğŸ“‚ Project Structure
ml-pipeline-tokenization/
â”œâ”€â”€ data/ # sample data (tiny CSVs, not sensitive!)
â”œâ”€â”€ models/ # trained models (ignored in .gitignore)
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ tokenization.py # build TF-IDF vocabulary
â”‚ â”œâ”€â”€ training.py # train logistic regression classifier
â”‚ â””â”€â”€ score.py # apply model and generate scores
â”œâ”€â”€ utils.py # helper functions
â”œâ”€â”€ requirements.txt # dependencies
â””â”€â”€ README.md


## âš¡ Quickstart

Clone the repository:
```bash
git clone git@github.com:saraandrade0/ml-pipeline-tokenization.git
cd ml-pipeline-tokenization
Create and activate a virtual environment:

Create and activate a virtual environment:

python -m venv .venv
source .venv/bin/activate   # macOS/Linux
.venv\Scripts\activate      # Windows

Install dependencies:
pip install -r requirements.txt

1ï¸âƒ£ Build the TF-IDF vectorizer

python src/tokenization.py

2ï¸âƒ£ Train the classifier

python src/training.py

3ï¸âƒ£ Score a dataset

python src/score.py data/samples.csv

Output:

models/tfidf.joblib

models/modelo_lr.joblib

scores.csv

ğŸ“Š Example Results
id	score
1	0.36524
2	0.68042
3	0.22093

ğŸ› ï¸ Tech Stack
Python 3.11+

pandas

scikit-learn

joblib

ğŸ”— Author
Made by Sara Andrade
Feel free to fork, star â­, and reach out if youâ€™d like to collaborate!